{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QshK8s21WBrf"
      },
      "source": [
        "# Week 07"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Hf8SXUwWOho"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Run the following 2 cells to import all necessary libraries and helpers for this week's exercises"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget -q https://github.com/DM-GY-9103-2024F-H/9103-utils/raw/main/src/data_utils.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "from data_utils import object_from_json_url\n",
        "from data_utils import MinMaxScaler, StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prKGt8bzScNA"
      },
      "source": [
        "## Dataset Exploration\n",
        "\n",
        "Let's revisit the house dataset from HW02."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L66UbgCWGDjF",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Define the location of the json file here\n",
        "HOUSES_FILE = \"https://raw.githubusercontent.com/DM-GY-9103-2024F-H/9103-utils/main/datasets/json/LA_housing.json\"\n",
        "\n",
        "houses_info = object_from_json_url(HOUSES_FILE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeWkaI_lYzIE"
      },
      "source": [
        "### Some \"light\" exploration:\n",
        "\n",
        "Ok. We should now have a list of objects with information about houses in LA.\n",
        "\n",
        "Let's work with the data to answer the following questions:\n",
        "- How many houses are in this dataset?\n",
        "- How many *features* does our dataset have? Features are the individual pieces of information about each house.\n",
        "- What are the *features*?\n",
        "- What's the min, max and average price for the houses in the dataset?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: fill out the code here to answer the questions about our dataset\n",
        "\n",
        "# How many houses are in the dataset?\n",
        "num_houses = 0\n",
        "\n",
        "# Features:\n",
        "house_features = []\n",
        "\n",
        "# Number of features:\n",
        "num_features = 0\n",
        "\n",
        "houses_info[0], house_features, num_houses, num_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get the info about the prices here\n",
        "\n",
        "We should probably create a separate list with just prices and then do the calculations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37h20s-9ZLY_",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# TODO: get statistics about house prices\n",
        "\n",
        "# List of prices\n",
        "house_prices = []\n",
        "\n",
        "# min price\n",
        "min_price = 0\n",
        "\n",
        "# max price\n",
        "max_price = 0\n",
        "\n",
        "# avg price\n",
        "avg_price = 0\n",
        "\n",
        "min_price, max_price, avg_price"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### More exploring\n",
        "\n",
        "What if we wanted to get `min`, `max` and `average` values for all of the features?\n",
        "\n",
        "# ðŸ˜–\n",
        "\n",
        "Repeating the code above, can get really annoying really quick, but hopefully we can use the `Pandas` library to help.\n",
        "\n",
        "Once we load our data into a `DataFrame` we can perform many types of calculations.\n",
        "\n",
        "Here's how we load our data into a `DataFrame`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "houses_df = pd.DataFrame.from_records(houses_info)\n",
        "\n",
        "# And we can check the first couple of rows/records with:\n",
        "houses_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DataFrame\n",
        "\n",
        "A `DataFrame` looks kind of like a spreadsheet. It has rows of items, and columns of features.\n",
        "\n",
        "<img src=\"./imgs/data_frame.jpg\" width=\"700px\">\n",
        "\n",
        "Now we have access to each feature by simply indexing the `DataFrame` by the feature's name.\n",
        "\n",
        "For example, to get the column with all of the prices and print the prices of the first $5$ houses in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "house_prices = houses_df[\"value\"]\n",
        "\n",
        "# print first 5\n",
        "house_prices.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get other columns\n",
        "\n",
        "Get the column with all of the ages of the houses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: get age column\n",
        "house_ages = \"\"\n",
        "house_ages.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Subsections\n",
        "\n",
        "We can also get a sub-section of our original data with only the `age` and `value` features, by indexing the original `DataFrame` with a list of the columns we want:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "house_ages_values = houses_df[[\"age\", \"value\"]]\n",
        "house_ages_values.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Doing some maths\n",
        "\n",
        "This is also easier with `DataFrames` because they have built-in math functions.\n",
        "\n",
        "To get the smallest value of a *feature*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "min_price = houses_df[\"value\"].min()\n",
        "min_price"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And the `average`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "avg_price = houses_df[\"value\"].mean()\n",
        "avg_price"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Other functions\n",
        "\n",
        "Try out the `count()`, `max()`, `sum()` and `median()` functions to get more information about the house prices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: find max, sum, median and count of the house prices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Getting column names\n",
        "\n",
        "This gives us a list with the names of the *features*/*columns*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "house_features = list(houses_df.columns)\n",
        "house_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It's similar to when we did `houses_info[0].keys()` above.\n",
        "\n",
        "Either way, we can now iterate over a list of the feature names to calculate `min`, `max` and `average` (and whatever else we want) for all of the *feature*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "for f in house_features:\n",
        "  print(f)\n",
        "  print(\"\\tmin:\", houses_df[f].min())\n",
        "  print(\"\\tmax:\", houses_df[f].max())\n",
        "  print(\"\\tavg:\", houses_df[f].mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can even ask for the `min` (or `max`, or `average`) of the whole `DataFrame` and it knows to do it for each column:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "houses_df.min()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Average / Mean\n",
        "\n",
        "The average, or mean, value of a set of numbers is a quantity that represents the center of a collection of numbers. What this means is that we expect about half of the numbers in a collection to be higher than the mean, and the other half to be lower.\n",
        "\n",
        "The mean of a set of numbers $x_1, x_2, ..., x_n$ is calculated by dividing the sum of the values by the number of values. It's sometimes written like this:\n",
        "\n",
        "$\\displaystyle \\mu = \\frac{1}{n} \\sum_{i=1}^{n} x_i$\n",
        "\n",
        "which is the same as `sum(X) / len(X)` in Python if `X` is our list of values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Standard Deviation\n",
        "\n",
        "In addition to the mean, the standard deviation is a measure of the amount of variation in a sequence of numbers.\n",
        "\n",
        "It's calculated by taking the square root of the average of the squared differences of each point to the mean of the sequence.\n",
        "\n",
        "In other words, first we calculate the difference between each point and the mean, and square this difference, then sum all of them up, divide by the number of values in the sequence, and finally take the square root:\n",
        "\n",
        "$\\displaystyle \\sigma = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} \\left(x_{i} - \\mu \\right)^{2}}$\n",
        "\n",
        "The standard deviation is a measurement of how close all of the points are to the mean.\n",
        "\n",
        "<img src=\"./imgs/std_dev.jpg\" width=\"800px\"/>\n",
        "\n",
        "Unfortunately, there is no short Python code for computing the standard deviation like there is for the average, but the `DataFrame` object has a function for computing it. It's called `std()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# mean and standard deviation for each feature\n",
        "for f in houses_df.columns:\n",
        "  print(f)\n",
        "  print(\"\\tavg:\", houses_df[f].mean())\n",
        "  print(\"\\tstd:\", houses_df[f].std())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that there's greater variability in the number of rooms of a house when compared to the number of bedrooms, but besides that, this isn't very useful yet because we can't really compare the standard deviations from different *features* that have different units.\n",
        "\n",
        "We'll see soon how we can use `mean` and `standard deviation` to compare, combine, extrapolate values that were measured in different units."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Correlation\n",
        "\n",
        "In week 02 we talked a little bit about correlation, and how it's a way to express how $2$ independent variables (measurements) are related to each other.\n",
        "\n",
        "<img src=\"./imgs/correlation.jpg\" width=\"800px\">\n",
        "\n",
        "Correlation can be *positive*, or, *direct*, if an increase in one of the variables comes with an increase in the other.\n",
        "\n",
        "It can be *negative*, or, *inverse*, if an increase in one of the variables is accompanied by a decrease in the other.\n",
        "\n",
        "Or, it can be *weak*, or, show *NO* correlation, if a change in one variable doesn't seem to be accompanied by a change in the other.\n",
        "\n",
        "### House Prices\n",
        "\n",
        "Let's say we want to figure out if there are any *features* that correlate strongly with the house prices.\n",
        "\n",
        "This means figuring out if there are any other *features* that are a good indication for the value of a house.\n",
        "\n",
        "We only have a handful of *features*, so we can always plot them.\n",
        "\n",
        "This is a lot easier with `DataFrames` because we don't have to separate our list of values from an object first. We can just give the `DataFrame` column to the plot function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.scatter(houses_df[\"age\"], houses_df[\"value\"], alpha=.1)\n",
        "plt.xlabel(\"age\")\n",
        "plt.ylabel(\"value\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot other features\n",
        "\n",
        "Even thought there aren't many features, we should really use a loop..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: use loop to plot ALL features compared to price"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Covariance Matrix\n",
        "\n",
        "Instead of looking at the plots there's actually a mathematical way of calculating how much the *features* of a dataset are *related*.\n",
        "\n",
        "It's called the [covariance](https://en.wikipedia.org/wiki/Covariance), and it measures how much $2$ *features* change together.\n",
        "\n",
        "One way to measure the covariance is to find the average of the product of pairs of differences of measurements and their means.\n",
        "\n",
        "# ðŸ¤”\n",
        "\n",
        "To calculate the covariance between `age` and `price` we would have to go through all of our data, subtract `age` and `price` values for each house from the average `age` and average `price`, multiply these differences together, and then sum up all of the products and divide by the total number of houses.\n",
        "\n",
        "$\\displaystyle cov(age,\\ price) = \\frac{1}{n} \\sum_{i}{(age_i - avg(age))\\ (price_i - avg(price))}$\n",
        "\n",
        "But, with our `DataFrame` we can just call a function that computes the covariance between any group of columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# covariance between age and price\n",
        "houses_df[[\"age\", \"value\"]].cov()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Try it out\n",
        "\n",
        "Computer some covariances and see if they match with the plots above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: display some other pairs of covariances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Displaying all of the covariances\n",
        "\n",
        "This will display a table/matrix that shows how much each variable is related to every other variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "houses_df.cov()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This will be useful when we start training models and want to reduce the amount of data we have to process, but for now we can just look at the covariances for the `value` *feature*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "houses_df.cov()[\"value\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we look at the *covariances* with the largest magnitudes, we can see that:\n",
        "- `value` correlates with `rooms`: the more rooms, the higher the price of a house.\n",
        "- `value` correlates inversely with `age`: the older the house, the less valuable it is.\n",
        "- `value` correlates somewhat with `longitude`.\n",
        "\n",
        "We skipped the largest magnitude of them all, because it's the correlation between `value` and itself, which should be high."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Normalizing / Standardizing / Scaling\n",
        "\n",
        "The above calculations give us some extra information about the data, but there are problems:\n",
        "\n",
        "All of the *features* are in different units. The range of the `rooms` *feature* is between $1$ and $17$, while the range of `age` is $2$ to $55$, and `latitude` and `longitude` vary by at most $1$ degree.\n",
        "\n",
        "Using different units to calculate the *covariance* can exaggerate how much certain *features* actually influence each other.\n",
        "\n",
        "In order to calculate *covariance* correctly we have to normalize the data in all columns to be *unitless*.\n",
        "\n",
        "One way to do this is to scale each value to be within the range $[0, 1]$ relative to the `min` and `max` values of their column.\n",
        "\n",
        "### [MinMax Scaling](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html):\n",
        "\n",
        "<img src=\"./imgs/scaling_min_max.jpg\" width=\"700px\">\n",
        "\n",
        "The math is not very complicated, it's actually exactly like the `map()` function from `p5.js`, but we're going to use a library that will do this for us because it can do on multiple columns at the same time and it will keep track of the changes we make to our original `DataFrame`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scale all the values to be between 0, 1\n",
        "\n",
        "# This creates a scaler object we can use\n",
        "min_max_scaler = MinMaxScaler()\n",
        "\n",
        "# This is how we use the object on our data\n",
        "houses_min_max_df = min_max_scaler.fit_transform(houses_df)\n",
        "\n",
        "# Scaled version of DataFrame\n",
        "houses_min_max_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now we can finally correctly calculate the covariances\n",
        "houses_min_max_df.cov()[\"value\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After we scale our features according to the `min` and `max` value of each column, `longitude` is the top feature that correlates with `value`, followed by `rooms` and then `age`.\n",
        "\n",
        "### [Standard Scaling](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
        "\n",
        "This is another type of *normalization* that uses the `mean` and `standard deviation` for each column to center their values at $0$ and have a range of about $[-3, 3]$.\n",
        "\n",
        "<img src=\"./imgs/scaling_std.jpg\" width=\"700px\">\n",
        "\n",
        "The math is very similar to `MinMax` scaling.\n",
        "\n",
        "One of the differences between `MinMax` and `Standard` scaling is that the range for `MinMax` is closed once we scale our data. If later, while collecting some new data, we see some value that is larger than the previously largest number, (or smallest than the smallest number), it will get scaled to something greater than $1$ (or less than $0$), and mess up our scaling.\n",
        "\n",
        "`Standard` scaling is a bit more resilient to this scenario because our range of $[-3, 3]$ is open. We can always get values larger than $3$, or smaller than $-3$, but they're unlikely. And, unless we collect a lot of new data with wildly different ranges, our `mean` and `std dev` will remain similar and our scaling will still work.\n",
        "\n",
        "`Standard` scaling is also available from the [Scikit-Learn](https://scikit-learn.org) library, so we can use it just like we used the `MinMax`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scale all the values to be centered at 0 and (mostly) within [-3, 3]\n",
        "\n",
        "# This creates a scaler object we can use\n",
        "std_scaler = StandardScaler()\n",
        "\n",
        "# This is how we use the object on our data\n",
        "houses_std_df = std_scaler.fit_transform(houses_df)\n",
        "\n",
        "# Scaled version of DataFrame\n",
        "houses_std_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now we can finally correctly calculate the covariances\n",
        "houses_std_df.cov()[\"value\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that if we scale our features according to the `mean` and `std dev` of each column, `longitude` is the top feature that correlates with `value`, followed by `rooms` and then `age`.\n",
        "\n",
        "In this case `MinMax` and `Standard` *scaling* are in agreement, but it's not always the case.\n",
        "\n",
        "Either way, *Normalizing* (or, *Standardizing*, or, *Scaling*) is an important step when working with data.\n",
        "\n",
        "This is not only true for calculating *covariances* and learning something about our datasets, but is even more important when training models with multiple *features*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## One more dataset\n",
        "\n",
        "Let's load..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the location of the json file here\n",
        "DIAMONDS_FILE = \"https://raw.githubusercontent.com/DM-GY-9103-2024F-H/9103-utils/main/datasets/json/diamonds.json\"\n",
        "\n",
        "# Read into Python object\n",
        "diamonds_data = object_from_json_url(DIAMONDS_FILE)\n",
        "\n",
        "# Create DataFrame\n",
        "diamonds_df = pd.DataFrame.from_records(diamonds_data)\n",
        "\n",
        "# Look at first few entries\n",
        "diamonds_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calculate some statistics for the features of this dataset\n",
        "\n",
        "Use a for loop to get `min()`, `max()`, `mean()` and `std()` for all features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: get min, max, mean, std for all features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ˜«\n",
        "\n",
        "Some of the *features* aren't even numerical, they're words/tags that describe some property of the diamond.\n",
        "\n",
        "We can still do some analysis. The easiest way is to just drop those columns:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diamonds_numerical_df = diamonds_df.drop(columns=[\"cut\", \"color\", \"clarity\"])\n",
        "diamonds_numerical_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Now we can get some statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Try the code from above again"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ¤·\n",
        "\n",
        "Which is fine if all we're doing is taking a look at our data, but once we start training models and doing more detailed analyses we'll want to use *ALL* of the data that we have available.\n",
        "\n",
        "Let's see how to work with non-numerical properties.\n",
        "\n",
        "### A Note About Features\n",
        "\n",
        "First, let's think about and organize the different types of *features* we have seen so far, or could see in the near future.\n",
        "\n",
        "We have some *features* that are represented by *continuous* values, like: `price` or `length`.\n",
        "\n",
        "We could have *features* that are represented by *ordered* discrete values, like: `clothing size` $(S, M, L)$, or `letter grades` $(A, B, C, D, F)$.\n",
        "\n",
        "And, we can also have *features* that are represented by *UNordered* discrete values (sometimes called *categories*), like: `primary colors` $(red, green, black)$, or `states` $(PA, NY, NJ)$.\n",
        "\n",
        "<img src=\"./imgs/encoding_00.jpg\" width=\"700px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Encoding\n",
        "\n",
        "In order to analyze datasets that have different types of *features*, it helps to be able to represent the *categorical* and *discrete* *features* in terms of numbers.\n",
        "\n",
        "This way we can perform the same types of transformations and calculations, like `mean`, `standard deviation` and `covariances`, on all of the *features* together.\n",
        "\n",
        "We'll achieve this by *encoding* these *features* using numbers. We'll create associations between the *feature* values and specific numbers, so we can easily transform these *categories* into numbers, do math, and then un-transform them back to *categories*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ordinal Encoding\n",
        "\n",
        "If the data that we want to encode has some kind of order, like with `letter grades`, where $A$ comes before $B$, which comes before $C$, and so on, we can use something called an [OrdinalEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html).\n",
        "\n",
        "We provide the order of the possible values of the *feature* and they will each get represented by a number in that same order:\n",
        "\n",
        "<img src=\"./imgs/encoding_ordinal.jpg\" width=\"700px\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### One-Hot Encoding\n",
        "\n",
        "If, however, the values we want to encode don't really have an oder, like `states`, or even `zip codes` (these are numbers, but it's not like we have a good reason for considering $10001$ *smaller* than $15201$), we can use an [OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html).\n",
        "\n",
        "This encoder turns each of the possible values of a *feature* into its own *feature*, and uses the numbers $0$ and $1$ to mark whether a *record* has that value or not:\n",
        "\n",
        "<img src=\"./imgs/encoding_one_hot.jpg\" width=\"700px\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Encoding Diamonds\n",
        "\n",
        "If we look at the [dataset info](https://www.kaggle.com/datasets/shivam2503/diamonds) for our diamond data, we'll see that all three of our *discrete* *features* have an order:\n",
        "\n",
        "<img src=\"./imgs/diamonds.jpg\" width=\"700px\"/>\n",
        "\n",
        "They all have a *worse* and a *best* option.\n",
        "\n",
        "This means we can use an [OrdinalEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html) to assign numbers to them and include them back into our dataset analysis and eventually use them for training models.\n",
        "\n",
        "To use the encoder, we first have to determine all the possible values of each of these features.\n",
        "\n",
        "Just like our `DataFrame` column objects have a `sum()` and `mean()` function, they also have a `unique()` function that gives us a list of unique values inside that column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diamonds_df[\"cut\"].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get values for `color` and `clarity` features\n",
        "\n",
        "We just need to take a look at these lists, so we can order them later when we create our encoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Get unique values for the 2 other features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, let's re-order them from worst to best:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cut_order = ['Fair', 'Good', 'Very Good', 'Premium', 'Ideal']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Repeat for `color` and `clarity`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: create ordered list of color and clarity values from worst to best\n",
        "\n",
        "color_order = []\n",
        "clarity_order = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating the encoder\n",
        "\n",
        "This is easy, we just have to give it the lists of possible values as an initialization parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diamond_encoder = OrdinalEncoder(categories=[cut_order, color_order, clarity_order])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Encode\n",
        "\n",
        "We have to apply the `Encoder` to our `DataFrame` columns, and then put the results back into our `DataFrame`.\n",
        "\n",
        "We'll overwrite the non-numeric values in the original columns, but we could create new columns for these if we wanted to have them both in the `DataFrame`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Encode the columns\n",
        "ccc_vals = diamond_encoder.fit_transform(diamonds_df[[\"cut\", \"color\", \"clarity\"]].values)\n",
        "\n",
        "# Put the values back in the original DataFrame\n",
        "diamonds_df[[\"cut\", \"color\", \"clarity\"]] = ccc_vals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get complete statistics\n",
        "\n",
        "We can now rerun our code to get statistics for all of our features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for f in diamonds_df.columns:\n",
        "  print(f)\n",
        "  print(\"\\tmin:\", diamonds_df[f].min())\n",
        "  print(\"\\tmax:\", diamonds_df[f].max())\n",
        "  print(\"\\tavg:\", diamonds_df[f].mean())\n",
        "  print(\"\\tstd:\", diamonds_df[f].std())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize features\n",
        "\n",
        "First, we'll normalize the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: scale all the values using either a MinMax or Standard scaler\n",
        "\n",
        "# Create a scaler object\n",
        "mscaler = \"\"\n",
        "\n",
        "# Use the object on our data\n",
        "diamonds_scaled_df = \"\"\n",
        "\n",
        "# Scaled version of DataFrame\n",
        "diamonds_scaled_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, look at covariance values for the `price` feature:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: look at covariance table for the price feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And, we can plot the normalized features, compared to `price`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the original data\n",
        "for f in diamonds_df.columns:\n",
        "  if f != \"price\":\n",
        "    plt.scatter(diamonds_df[f], diamonds_df[\"price\"], alpha=.1)\n",
        "    plt.xlabel(f)\n",
        "    plt.ylabel(\"price\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next time: Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "from data_utils import object_from_json_url\n",
        "from data_utils import LinearRegression, MinMaxScaler\n",
        "\n",
        "# Load Dataset\n",
        "DIAMONDS_FILE = \"https://raw.githubusercontent.com/DM-GY-9103-2024F-H/9103-utils/main/datasets/json/diamonds.json\"\n",
        "\n",
        "# Read into DataFrame\n",
        "diamonds_data = object_from_json_url(DIAMONDS_FILE)\n",
        "diamonds_df = pd.DataFrame.from_records(diamonds_data)\n",
        "\n",
        "\n",
        "# Encode\n",
        "cut_order = ['Fair', 'Good', 'Very Good', 'Premium', 'Ideal']\n",
        "color_order = ['J', 'I', 'H', 'G', 'F', 'E', 'D']\n",
        "clarity_order = ['I1', 'SI2', 'SI1', 'VS2', 'VS1', 'VVS2', 'VVS1', 'IF']\n",
        "\n",
        "diamond_encoder = OrdinalEncoder(categories=[cut_order, color_order, clarity_order])\n",
        "\n",
        "ccc_vals = diamond_encoder.fit_transform(diamonds_df[[\"cut\", \"color\", \"clarity\"]].values)\n",
        "diamonds_df[[\"cut\", \"color\", \"clarity\"]] = ccc_vals\n",
        "\n",
        "\n",
        "# Normalize\n",
        "diamond_scaler = MinMaxScaler()\n",
        "diamonds_scaled = diamond_scaler.fit_transform(diamonds_df)\n",
        "\n",
        "\n",
        "# Linear Regression\n",
        "price_model = LinearRegression()\n",
        "\n",
        "# Get prices and features\n",
        "prices = diamonds_scaled[\"price\"]\n",
        "features = diamonds_scaled.drop(columns=[\"price\"])\n",
        "\n",
        "# Build the model\n",
        "price_model.fit(features, prices)\n",
        "\n",
        "# Run the model on the training data\n",
        "predicted_scaled = price_model.predict(features)\n",
        "\n",
        "\n",
        "# Un-normalize the data\n",
        "predicted = diamond_scaler.inverse_transform(predicted_scaled)\n",
        "\n",
        "\n",
        "# Measure Model error\n",
        "price_mse = mean_squared_error(diamonds_df[\"price\"].values, predicted[\"price\"].values, squared=False)\n",
        "print(price_mse)\n",
        "\n",
        "\n",
        "# Plot predictions\n",
        "carats = diamonds_scaled[[\"carat\"]]\n",
        "\n",
        "plt.plot(sorted(prices), marker='o', markersize=8)\n",
        "plt.plot(sorted(predicted_scaled[\"price\"]), marker='o', markersize=2, linestyle='', color='r')\n",
        "plt.title(\"sorted prices\")\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(carats, prices, marker='o', linestyle='', alpha=0.3)\n",
        "plt.scatter(carats, predicted_scaled, color='r', marker='o', linestyle='', alpha=0.1)\n",
        "plt.xlabel(\"carat\")\n",
        "plt.ylabel(\"price\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPxe2qYxIG7EblrvD1C4Pmv",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.17 ('hf-model')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "89e384cab7c47fb35ec95d2248b519cf922ee174880eed636c26cdfb6c4df768"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
